{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFnf7CuWQuT7",
        "colab_type": "code",
        "outputId": "ff475fec-00ac-45b3-b219-24bba6f88251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe5535953f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHQ_ELCASg19",
        "colab": {}
      },
      "source": [
        "def zero_pad(X, pad):\n",
        "    _pad = nn.ZeroPad2d(pad)\n",
        "    X_pad = _pad(X)\n",
        "    \n",
        "    \n",
        "    return X_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHMr0qynQuUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "X = torch.randn(4,2,3,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhN4IY_IT14O",
        "colab_type": "code",
        "outputId": "c631c3bd-12ba-4347-8e85-6ef49042f1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "x_pad = zero_pad(X, 2)\n",
        "print (\"x.shape =\\n\", X.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[1,1] =\\n\", X[1,1])\n",
        "print (\"x_pad[1,1] =\\n\", x_pad[1,1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(X[0,0,:,:])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,0,:,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape =\n",
            " torch.Size([4, 2, 3, 3])\n",
            "x_pad.shape =\n",
            " torch.Size([4, 2, 7, 7])\n",
            "x[1,1] =\n",
            " tensor([[-1.4465,  0.0612, -0.6177],\n",
            "        [-0.7981, -0.1316,  1.8793],\n",
            "        [-0.0721,  0.1578, -0.7735]])\n",
            "x_pad[1,1] =\n",
            " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, -1.4465,  0.0612, -0.6177,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, -0.7981, -0.1316,  1.8793,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, -0.0721,  0.1578, -0.7735,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe54e865400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAACuCAYAAABOQnSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niGZmyf8BkxY8MFUfwmAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tmfgadi6oX_E",
        "colab": {}
      },
      "source": [
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    s = a_slice_prev * W \n",
        "    Z =  torch.sum(s)\n",
        "    Z = Z + float(b)\n",
        "\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp8UZxmWQuUI",
        "colab_type": "code",
        "outputId": "6e6a8207-e887-4f53-ba43-cbb551d437c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "a_slice_prev = torch.randn(3,4,4)\n",
        "W = torch.randn(3,4,4)\n",
        "b = torch.randn(1,1,1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = tensor(-8.5554)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LHGSapNxX6zr",
        "colab": {}
      },
      "source": [
        "def conv_forward(A_prev, W, b, hparameters): \n",
        "    (m, n_C_prev, n_H_prev, n_W_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve dimensions from W's shape \n",
        "    (n_C_prev, f, f, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
        "    n_H = int((n_H_prev+(2*pad)-f)/stride) + 1\n",
        "    n_W = int((n_W_prev+(2*pad)-f)/stride) + 1 \n",
        "    \n",
        "    # Initialize the output volume Z with zeros. \n",
        "    Z = torch.zeros((m,n_C,n_H,n_W))\n",
        "\n",
        "    \n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    _pad = nn.ZeroPad2d(pad)   \n",
        "    A_prev_pad = _pad(A_prev)\n",
        "    \n",
        "    for i in range(m):               # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i,:,:,:]               # Select ith training example's padded activation\n",
        "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
        "            # Find the vertical start and end of the current \"slice\"\n",
        "            vert_start = h*stride\n",
        "            vert_end = (h*stride)+f\n",
        "                       \n",
        "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
        "                # Find the horizontal start and end of the current \"slice\"\n",
        "                horiz_start = w*stride\n",
        "                horiz_end = (w*stride)+f\n",
        "                \n",
        "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
        "                                        \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). \n",
        "                    a_slice_prev = a_prev_pad[:,vert_start : vert_end,horiz_start :horiz_end]\n",
        "                    \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
        "                    weights = W[:,:,:,c]\n",
        "                    biases = b[:,:,:,c]\n",
        "                    Z[i, c, h, w] = conv_single_step(a_slice_prev, weights, biases)\n",
        "                                        \n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_C, n_H, n_W))\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gjoI3jfQuUP",
        "colab_type": "code",
        "outputId": "0c287fff-592e-42df-d5c1-3640f0b493aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "torch.manual_seed(1)\n",
        "A_prev = torch.randn(10,4,5,7)\n",
        "W = torch.randn(4,3,3,8)\n",
        "b = torch.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 1,\n",
        "               \"stride\": 2}\n",
        "\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\\n\", torch.mean(Z))\n",
        "print(\"Z[3,2,1] =\\n\", Z[3,:,2,1])\n",
        "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z's mean =\n",
            " tensor(-0.3294)\n",
            "Z[3,2,1] =\n",
            " tensor([ 0.5648,  3.0823,  5.3929, -0.4358, -1.9275,  7.4754, -2.3530, -4.6575])\n",
            "cache_conv[0][1][2][3] =\n",
            " tensor([ 0.3872, -0.0798,  0.3417,  0.9488, -1.3839,  1.7241, -2.3648])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI736CMHQuUS",
        "colab_type": "text"
      },
      "source": [
        "Finally, CONV layer should also contain an activation, in which case we would add the following line of code:\n",
        "\n",
        "```python\n",
        "# Convolve the window to get back one output neuron\n",
        "Z[i, c, h, w] = ...\n",
        "# Apply activation\n",
        "A[i, c, h, w] = activation(Z[i, c, h, w])\n",
        "```\n",
        "\n",
        "You don't need to do it here. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yFQS1KFCoJLm",
        "colab": {}
      },
      "source": [
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_C_prev, n_H_prev, n_W_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = torch.zeros((m, n_C, n_H, n_W))              \n",
        "    \n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            # Find the vertical start and end of the current \"slice\" \n",
        "            vert_start = vert_start = (stride*h) \n",
        "            vert_end = (stride*h) + f\n",
        "        \n",
        "            \n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                # Find the vertical start and end of the current \"slice\" \n",
        "                horiz_start = horiz_start =(stride*w) \n",
        "                horiz_end = (stride*w) +f\n",
        "                \n",
        "                for c in range (n_C):            # loop over the channels of the output volume                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. \n",
        "                    a_prev_slice = A_prev[i,vert_start:vert_end , horiz_start : horiz_end , c]\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. \n",
        "                    # Use an if statement to differentiate the modes. \n",
        "                    # Use torch.max and torch.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, c, h, w] = torch.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, c, h, w] = torch.mean(a_prev_slice)\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_C, n_H, n_W))\n",
        "    \n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt9pzfr4QuUV",
        "colab_type": "code",
        "outputId": "28b2ebae-12d7-4ed4-ce0b-b2fc0be62c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Case 1: stride of 1\n",
        "torch.manual_seed(1)\n",
        "A_prev = torch.randn(2, 3, 5, 5)\n",
        "hparameters = {\"stride\" : 1, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A.shape = torch.Size([2, 3, 3, 3])\n",
            "A =\n",
            " tensor([[[[ 2.0154,  2.0154,  1.6734],\n",
            "          [ 2.0154,  2.0154,  1.6734],\n",
            "          [ 2.0154,  2.0154,  1.6734]],\n",
            "\n",
            "         [[ 0.1991,  0.2927,  1.5748],\n",
            "          [ 0.1991,  0.2927,  1.5748],\n",
            "          [ 0.1374,  0.1374,  0.0103]],\n",
            "\n",
            "         [[ 1.8793,  1.8793,  0.0457],\n",
            "          [ 1.8793,  1.8793,  0.0457],\n",
            "          [ 0.9386,  0.9386, -0.7040]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7986,  0.8168,  2.5581],\n",
            "          [ 1.7986,  0.8168,  2.5581],\n",
            "          [ 1.7986,  0.3539,  0.0375]],\n",
            "\n",
            "         [[ 1.1996,  1.1996,  0.7575],\n",
            "          [ 1.1996,  1.1996,  0.7575],\n",
            "          [ 1.1996,  1.1996,  0.7575]],\n",
            "\n",
            "         [[ 0.8738,  0.8738,  1.1899],\n",
            "          [ 0.8738,  0.8738,  0.8738],\n",
            "          [ 0.3400, -0.3030, -0.4068]]]])\n",
            "\n",
            "mode = average\n",
            "A.shape = torch.Size([2, 3, 3, 3])\n",
            "A =\n",
            " tensor([[[[-1.1540e-01, -7.7895e-03,  9.1505e-02],\n",
            "          [ 3.1224e-01,  1.4146e-01,  4.4588e-02],\n",
            "          [ 1.2070e+00,  8.4377e-01,  7.2978e-01]],\n",
            "\n",
            "         [[-5.9209e-01, -3.2182e-01, -1.0318e-02],\n",
            "          [-5.5789e-01, -1.6137e-01,  1.0186e-01],\n",
            "          [-3.8974e-01, -4.4279e-01, -4.8514e-01]],\n",
            "\n",
            "         [[-4.0407e-01, -5.1366e-01, -8.6984e-01],\n",
            "          [-1.9189e-01, -2.7181e-01, -9.6377e-01],\n",
            "          [-5.4330e-01, -1.1327e+00, -1.6802e+00]]],\n",
            "\n",
            "\n",
            "        [[[-8.0254e-02, -3.6241e-01, -2.6489e-02],\n",
            "          [ 1.8604e-01, -2.0220e-01, -1.1452e-01],\n",
            "          [ 2.0169e-01, -3.8535e-01, -8.6127e-01]],\n",
            "\n",
            "         [[-2.0157e-02,  1.4349e-01,  3.5778e-02],\n",
            "          [ 1.3665e-03,  4.7950e-02, -2.0722e-01],\n",
            "          [ 6.8630e-01,  4.3975e-01, -2.7290e-02]],\n",
            "\n",
            "         [[-2.1653e-01, -2.5008e-01, -5.8486e-02],\n",
            "          [-9.5792e-02, -6.4740e-02, -8.4660e-02],\n",
            "          [-1.2325e-01, -4.7204e-01, -5.5780e-01]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWJgdWsVQuUY",
        "colab_type": "code",
        "outputId": "6c345ffc-7af9-405a-9074-f535429cdde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "# Case 2: stride of 2\n",
        "torch.manual_seed(1)\n",
        "A_prev = torch.randn(2, 3, 5, 5)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)\n",
        "print()\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A.shape = torch.Size([2, 3, 2, 2])\n",
            "A =\n",
            " tensor([[[[ 2.0154,  1.6734],\n",
            "          [ 2.0154,  1.6734]],\n",
            "\n",
            "         [[ 0.1991,  1.5748],\n",
            "          [ 0.1374,  0.0103]],\n",
            "\n",
            "         [[ 1.8793,  0.0457],\n",
            "          [ 0.9386, -0.7040]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7986,  2.5581],\n",
            "          [ 1.7986,  0.0375]],\n",
            "\n",
            "         [[ 1.1996,  0.7575],\n",
            "          [ 1.1996,  0.7575]],\n",
            "\n",
            "         [[ 0.8738,  1.1899],\n",
            "          [ 0.3400, -0.4068]]]])\n",
            "\n",
            "mode = average\n",
            "A.shape = torch.Size([2, 3, 2, 2])\n",
            "A =\n",
            " tensor([[[[-0.1154,  0.0915],\n",
            "          [ 1.2070,  0.7298]],\n",
            "\n",
            "         [[-0.5921, -0.0103],\n",
            "          [-0.3897, -0.4851]],\n",
            "\n",
            "         [[-0.4041, -0.8698],\n",
            "          [-0.5433, -1.6802]]],\n",
            "\n",
            "\n",
            "        [[[-0.0803, -0.0265],\n",
            "          [ 0.2017, -0.8613]],\n",
            "\n",
            "         [[-0.0202,  0.0358],\n",
            "          [ 0.6863, -0.0273]],\n",
            "\n",
            "         [[-0.2165, -0.0585],\n",
            "          [-0.1233, -0.5578]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}